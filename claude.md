# éŸ³å£°éŒ²éŸ³ã‚·ã‚¹ãƒ†ãƒ é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰

## ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

ãƒ–ãƒ©ã‚¦ã‚¶å´ã§VADï¼ˆVoice Activity Detectionï¼‰å‡¦ç†ã‚’è¡Œã†è»½é‡ãªéŸ³å£°éŒ²éŸ³ã‚·ã‚¹ãƒ†ãƒ ã€‚
è©±ã—ã¦ã„ã‚‹æ™‚ã ã‘è‡ªå‹•ã§éŒ²éŸ³ã—ã€ç„¡éŸ³éƒ¨åˆ†ã¯ã‚«ãƒƒãƒˆã—ã¦åŠ¹ç‡çš„ã«ä¿å­˜ã€‚

## ğŸ—ï¸ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰**: Vue 3 + TypeScript + Vite
- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰**: Python + FastAPI
- **éŸ³å£°å‡¦ç†**: WebRTC VADï¼ˆãƒ–ãƒ©ã‚¦ã‚¶å´ï¼‰
- **é€šä¿¡**: WebSocket

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰

```
voice-recorder/
â”œâ”€â”€ .env                    # ç’°å¢ƒå¤‰æ•°ï¼ˆå…±é€šï¼‰
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ package.json            # npmä¾å­˜é–¢ä¿‚
â”œâ”€â”€ pyproject.toml          # Pythonä¾å­˜é–¢ä¿‚ï¼ˆryeï¼‰
â”œâ”€â”€ index.html              # Viteã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ vite.config.ts          # Viteè¨­å®š
â”œâ”€â”€ tsconfig.json           # TypeScriptè¨­å®š
â”œâ”€â”€ server.py               # FastAPIã‚µãƒ¼ãƒãƒ¼ï¼ˆ1ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
â”œâ”€â”€ src/                    # Vueã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ main.ts
â”‚   â”œâ”€â”€ App.vue
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ AudioRecorder.vue
â”‚   â”‚   â”œâ”€â”€ AudioVisualizer.vue
â”‚   â”‚   â””â”€â”€ SettingsPanel.vue
â”‚   â”œâ”€â”€ composables/
â”‚   â”‚   â”œâ”€â”€ useWebRTCVAD.ts
â”‚   â”‚   â””â”€â”€ useAudioRecorder.ts
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ audioBuffer.ts
â”œâ”€â”€ public/                 # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«
â””â”€â”€ recordings/             # éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å…ˆ
```

## âš™ï¸ ç’°å¢ƒè¨­å®šï¼ˆ.envï¼‰

```bash
# ã‚µãƒ¼ãƒãƒ¼è¨­å®š
API_HOST=127.0.0.1
API_PORT=8000

# Viteç”¨è¨­å®šï¼ˆVITE_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹å¿…é ˆï¼‰
VITE_API_BASE_URL=http://127.0.0.1:8000
VITE_WS_URL=ws://127.0.0.1:8000/ws

# ã‚¢ãƒ—ãƒªè¨­å®š
AUDIO_SAVE_PATH=./recordings
DEBUG=true
```

## ğŸ”§ ä¸»è¦æ©Ÿèƒ½

### 1. å¸¸æ™‚éŸ³å£°ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
- **éŒ²éŸ³ã—ã¦ã„ãªã„æ™‚ã‚‚å¸¸ã«ãƒã‚¤ã‚¯ON**
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ï¼ˆdBè¡¨ç¤ºï¼‰
- VADçŠ¶æ…‹è¡¨ç¤ºï¼ˆéŸ³å£°æ¤œå‡ºä¸­ã¯ç·‘ã€ç„¡éŸ³ã¯ç°è‰²ãªã©ï¼‰
- éŸ³å£°æ³¢å½¢ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
- ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼

### 2. ãƒ–ãƒ©ã‚¦ã‚¶å´å‡¦ç†ï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
- ãƒã‚¤ã‚¯éŸ³å£°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§VADå‡¦ç†
- éŸ³å£°åŒºé–“ã®è‡ªå‹•æ¤œå‡º
- éŒ²éŸ³ãƒœã‚¿ãƒ³ã§éŒ²éŸ³é–‹å§‹/åœæ­¢ï¼ˆæ‰‹å‹•ï¼‰
- è‡ªå‹•éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆVADæ¤œå‡ºã§è‡ªå‹•éŒ²éŸ³ï¼‰

### 2. VADè¨­å®š
```typescript
// ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­å®šæ§‹é€ 
interface Settings {
  vad: {
    algorithm: 'webrtc' | 'energy';
    sensitivity: 0 | 1 | 2 | 3;  // WebRTC VAD Mode
    timing: {
      speechPadStart: number;     // éŸ³å£°å‰ã®ä½™ç™½ (ms)
      speechPadEnd: number;       // éŸ³å£°å¾Œã®ä½™ç™½ (ms)
      minSpeechDuration: number;  // æœ€å°éŸ³å£°é•· (ms)
      maxSilenceDuration: number; // æœ€å¤§ç„¡éŸ³é•· (ms)
    };
  };
  audio: {
    sampleRate: 16000 | 44100;
    format: 'wav' | 'webm';
  };
}
```

### 3. å‡¦ç†ãƒ•ãƒ­ãƒ¼
```
[å¸¸æ™‚ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°]
ãƒã‚¤ã‚¯ â†’ Web Audio API â†’ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è§£æ
                         â”œâ”€ éŸ³é‡è¨ˆç®— â†’ ãƒ¡ãƒ¼ã‚¿ãƒ¼è¡¨ç¤º
                         â”œâ”€ VADå‡¦ç† â†’ çŠ¶æ…‹è¡¨ç¤º
                         â””â”€ æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ â†’ Canvasæç”»

[éŒ²éŸ³æ™‚]
éŒ²éŸ³ãƒœã‚¿ãƒ³ON â†’ éŸ³å£°ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°é–‹å§‹
              â†’ VADæ¤œå‡ºæ™‚ã®ã¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
              â†’ éŒ²éŸ³åœæ­¢ â†’ ã‚µãƒ¼ãƒãƒ¼é€ä¿¡
```

### 4. å‹•ä½œãƒ¢ãƒ¼ãƒ‰
- **ãƒ¢ãƒ‹ã‚¿ãƒ¼ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰**: å¸¸æ™‚ãƒã‚¤ã‚¯ONã€è¡¨ç¤ºã®ã¿
- **æ‰‹å‹•éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰**: éŒ²éŸ³ãƒœã‚¿ãƒ³ã§é–‹å§‹/åœæ­¢
- **è‡ªå‹•éŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰**: VADæ¤œå‡ºã§è‡ªå‹•çš„ã«éŒ²éŸ³é–‹å§‹/åœæ­¢

## ğŸ’» å®Ÿè£…

### .gitignore

```gitignore
# Dependencies
node_modules/
.rye/
__pycache__/

# Environment
.env
.env.local

# Build outputs
dist/
build/

# Recordings
recordings/

# IDE
.vscode/
.idea/

# OS
.DS_Store
```

### vite.config.ts

```typescript
import { defineConfig } from 'vite'
import vue from '@vitejs/plugin-vue'

export default defineConfig({
  plugins: [vue()],
  server: {
    port: 5173,
    proxy: {
      '/api': {
        target: 'http://127.0.0.1:8000',
        changeOrigin: true,
      },
    },
  },
})
```

### tsconfig.json

```json
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "module": "ESNext",
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "skipLibCheck": true,
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "preserve",
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true
  },
  "include": ["src/**/*.ts", "src/**/*.d.ts", "src/**/*.tsx", "src/**/*.vue"],
  "references": [{ "path": "./tsconfig.node.json" }]
}
```

### tsconfig.node.json

```json
{
  "compilerOptions": {
    "composite": true,
    "skipLibCheck": true,
    "module": "ESNext",
    "moduleResolution": "bundler",
    "allowSyntheticDefaultImports": true
  },
  "include": ["vite.config.ts"]
}
```

### server.pyï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãª1ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰

```python
from fastapi import FastAPI, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
import os
import json
from datetime import datetime
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

app = FastAPI()

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šå–å¾—
API_HOST = os.getenv("API_HOST", "127.0.0.1")
API_PORT = int(os.getenv("API_PORT", "8000"))
AUDIO_SAVE_PATH = os.getenv("AUDIO_SAVE_PATH", "./recordings")

# CORSè¨­å®šï¼ˆé–‹ç™ºç”¨ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# éŒ²éŸ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
os.makedirs(AUDIO_SAVE_PATH, exist_ok=True)

@app.get("/")
async def health():
    return {"status": "ok", "time": datetime.now()}

@app.websocket("/ws/audio")
async def audio_ws(websocket: WebSocket):
    await websocket.accept()
    try:
        while True:
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿å—ä¿¡
            data = await websocket.receive_bytes()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"recording_{timestamp}.wav"
            filepath = os.path.join(AUDIO_SAVE_PATH, filename)
            
            with open(filepath, "wb") as f:
                f.write(data)
            
            # çµæœè¿”ä¿¡
            await websocket.send_json({
                "filename": filename,
                "size": len(data),
                "timestamp": timestamp
            })
    except:
        pass

@app.get("/recordings")
async def list_recordings():
    files = []
    for f in os.listdir(AUDIO_SAVE_PATH):
        if f.endswith((".wav", ".webm")):
            filepath = os.path.join(AUDIO_SAVE_PATH, f)
            files.append({
                "name": f,
                "size": os.path.getsize(filepath),
                "created": os.path.getctime(filepath)
            })
    return {"recordings": files}

@app.get("/recordings/{filename}")
async def get_recording(filename: str):
    filepath = os.path.join(AUDIO_SAVE_PATH, filename)
    if os.path.exists(filepath):
        return FileResponse(filepath)
    return {"error": "File not found"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host=API_HOST, port=API_PORT)
```

### package.jsonï¼ˆå¿…è¦æœ€å°é™ï¼‰

```json
{
  "name": "voice-recorder",
  "version": "1.0.0",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "serve": "rye run python server.py",
    "start": "concurrently \"npm run serve\" \"npm run dev\""
  },
  "dependencies": {
    "vue": "^3.4.0",
    "element-plus": "^2.7.0",
    "@ricky0123/vad-web": "^0.0.7"
  },
  "devDependencies": {
    "@vitejs/plugin-vue": "^5.0.0",
    "@types/node": "^20.0.0",
    "vite": "^5.0.0",
    "typescript": "^5.0.0",
    "concurrently": "^8.0.0"
  }
}
```

### pyproject.tomlï¼ˆryeç”¨ï¼‰

```toml
[project]
name = "voice-recorder"
version = "0.1.0"
description = "Voice recorder with VAD"
dependencies = [
    "fastapi>=0.115.0",
    "uvicorn>=0.30.0",
    "python-multipart>=0.0.9",
    "websockets>=12.0",
    "python-dotenv>=1.0.0",
]
requires-python = ">= 3.11"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.rye]
managed = true
dev-dependencies = []
```

## ğŸš€ èµ·å‹•æ–¹æ³•

```bash
# Pythonç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆryeï¼‰
rye sync

# Nodeä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
npm install

# é–‹ç™ºã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆä¸¡æ–¹åŒæ™‚ï¼‰
npm start

# ã¾ãŸã¯å€‹åˆ¥ã«èµ·å‹•
# ã‚¿ãƒ¼ãƒŸãƒŠãƒ«1
rye run python server.py

# ã‚¿ãƒ¼ãƒŸãƒŠãƒ«2
npm run dev
```

## ğŸ“ é–‹ç™ºæ‰‹é †

### Step 1: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–
```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
mkdir voice-recorder && cd voice-recorder

# Pythonç’°å¢ƒï¼ˆryeï¼‰
rye init
# pyproject.tomlã‚’ä¸Šè¨˜ã®å†…å®¹ã«ç·¨é›†
rye sync

# Nodeç’°å¢ƒ
npm init -y
# package.jsonã‚’ä¸Šè¨˜ã®å†…å®¹ã«ç·¨é›†
npm install
```

### Step 2: åŸºæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

**index.html**
```html
<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice Recorder</title>
</head>
<body>
  <div id="app"></div>
  <script type="module" src="/src/main.ts"></script>
</body>
</html>
```

**src/main.ts**
```typescript
import { createApp } from 'vue'
import ElementPlus from 'element-plus'
import 'element-plus/dist/index.css'
import App from './App.vue'

const app = createApp(App)
app.use(ElementPlus)
app.mount('#app')
```

**src/App.vue**
```vue
<template>
  <div class="container">
    <h1>Voice Recorder with VAD</h1>
    <AudioMonitor />
    <AudioRecorder />
  </div>
</template>

<script setup lang="ts">
import AudioMonitor from './components/AudioMonitor.vue'
import AudioRecorder from './components/AudioRecorder.vue'
</script>

<style>
.container {
  max-width: 800px;
  margin: 0 auto;
  padding: 20px;
}
</style>
```

**src/components/AudioMonitor.vueï¼ˆå¸¸æ™‚è¡¨ç¤ºï¼‰**
```vue
<template>
  <div class="audio-monitor">
    <div class="monitor-section">
      <h3>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ‹ã‚¿ãƒ¼</h3>
      
      <!-- éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ -->
      <div class="volume-meter">
        <label>éŸ³é‡ãƒ¬ãƒ™ãƒ«: {{ volumeDb }} dB</label>
        <el-progress 
          :percentage="volumePercentage" 
          :color="volumeColor"
          :stroke-width="20"
        />
      </div>
      
      <!-- VADçŠ¶æ…‹ -->
      <div class="vad-status">
        <span :class="['status-dot', { active: isSpeaking }]"></span>
        <span>{{ isSpeaking ? 'éŸ³å£°æ¤œå‡ºä¸­' : 'ç„¡éŸ³' }}</span>
      </div>
      
      <!-- æ³¢å½¢è¡¨ç¤º -->
      <canvas ref="waveformCanvas" width="600" height="100"></canvas>
      
      <!-- ç’°å¢ƒãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ« -->
      <div class="noise-level">
        <label>ç’°å¢ƒãƒã‚¤ã‚º: {{ noiseLevel }} dB</label>
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted } from 'vue'
import { useAudioMonitor } from '../composables/useAudioMonitor'

const volumeDb = ref(-60)
const volumePercentage = ref(0)
const isSpeaking = ref(false)
const noiseLevel = ref(-50)
const waveformCanvas = ref<HTMLCanvasElement>()

const volumeColor = computed(() => {
  if (volumeDb.value > -10) return '#f56c6c' // èµ¤ï¼ˆéŸ³é‡å¤§ï¼‰
  if (volumeDb.value > -30) return '#e6a23c' // ã‚ªãƒ¬ãƒ³ã‚¸
  return '#67c23a' // ç·‘ï¼ˆé©æ­£ï¼‰
})

const { startMonitoring, stopMonitoring } = useAudioMonitor({
  onVolumeUpdate: (db: number, percentage: number) => {
    volumeDb.value = db
    volumePercentage.value = percentage
  },
  onVadUpdate: (speaking: boolean) => {
    isSpeaking.value = speaking
  },
  onWaveformUpdate: (data: Float32Array) => {
    drawWaveform(data)
  },
  onNoiseLevel: (level: number) => {
    noiseLevel.value = level
  }
})

onMounted(() => {
  startMonitoring()
})

onUnmounted(() => {
  stopMonitoring()
})

// æ³¢å½¢æç”»
function drawWaveform(data: Float32Array) {
  const canvas = waveformCanvas.value
  if (!canvas) return
  
  const ctx = canvas.getContext('2d')!
  const width = canvas.width
  const height = canvas.height
  
  ctx.fillStyle = '#f5f5f5'
  ctx.fillRect(0, 0, width, height)
  
  ctx.lineWidth = 2
  ctx.strokeStyle = isSpeaking.value ? '#67c23a' : '#909399'
  ctx.beginPath()
  
  const sliceWidth = width / data.length
  let x = 0
  
  for (let i = 0; i < data.length; i++) {
    const v = data[i]
    const y = (v + 1) / 2 * height
    
    if (i === 0) {
      ctx.moveTo(x, y)
    } else {
      ctx.lineTo(x, y)
    }
    
    x += sliceWidth
  }
  
  ctx.stroke()
}
</script>

<style scoped>
.audio-monitor {
  background: #f5f5f5;
  padding: 20px;
  border-radius: 8px;
  margin-bottom: 20px;
}

.status-dot {
  display: inline-block;
  width: 12px;
  height: 12px;
  border-radius: 50%;
  background: #ccc;
  margin-right: 8px;
}

.status-dot.active {
  background: #67c23a;
  animation: pulse 1s infinite;
}

@keyframes pulse {
  0% { opacity: 1; }
  50% { opacity: 0.5; }
  100% { opacity: 1; }
}
</style>
```

### Step 3: VADå®Ÿè£…
1. VADãƒ©ã‚¤ãƒ–ãƒ©ãƒªçµ±åˆï¼ˆ@ricky0123/vad-webä½¿ç”¨ï¼‰
2. `useWebRTCVAD.ts` composableä½œæˆ
3. éŸ³å£°ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å®Ÿè£…

**æ³¨**: ãƒ–ãƒ©ã‚¦ã‚¶ç”¨WebRTC VADãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã„ãã¤ã‹é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™ï¼š
- `@ricky0123/vad-web`: Silero VADã®WebAssemblyç‰ˆ
- è‡ªå‰å®Ÿè£…: Web Audio APIã§ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ™ãƒ¼ã‚¹VAD
- TensorFlow.js: ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«

**src/composables/useAudioMonitor.tsï¼ˆå¸¸æ™‚ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ç”¨ï¼‰**
```typescript
import { ref, onUnmounted } from 'vue'

interface AudioMonitorOptions {
  onVolumeUpdate: (db: number, percentage: number) => void
  onVadUpdate: (isSpeaking: boolean) => void
  onWaveformUpdate: (data: Float32Array) => void
  onNoiseLevel: (level: number) => void
}

export function useAudioMonitor(options: AudioMonitorOptions) {
  let audioContext: AudioContext | null = null
  let analyser: AnalyserNode | null = null
  let microphone: MediaStreamAudioSourceNode | null = null
  let animationId: number | null = null
  
  const isMonitoring = ref(false)
  
  async function startMonitoring() {
    try {
      // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: false
        } 
      })
      
      // Audio Contextè¨­å®š
      audioContext = new AudioContext()
      analyser = audioContext.createAnalyser()
      analyser.fftSize = 2048
      analyser.smoothingTimeConstant = 0.8
      
      microphone = audioContext.createMediaStreamSource(stream)
      microphone.connect(analyser)
      
      isMonitoring.value = true
      
      // ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ«ãƒ¼ãƒ—
      const dataArray = new Float32Array(analyser.frequencyBinCount)
      
      function updateMonitor() {
        if (!isMonitoring.value) return
        
        analyser!.getFloatTimeDomainData(dataArray)
        
        // éŸ³é‡è¨ˆç®—ï¼ˆRMSï¼‰
        let sum = 0
        for (let i = 0; i < dataArray.length; i++) {
          sum += dataArray[i] * dataArray[i]
        }
        const rms = Math.sqrt(sum / dataArray.length)
        const db = 20 * Math.log10(rms)
        const percentage = Math.min(100, Math.max(0, (db + 60) * 1.67))
        
        options.onVolumeUpdate(Math.round(db), Math.round(percentage))
        
        // ç°¡æ˜“VADï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ™ãƒ¼ã‚¹ï¼‰
        const isSpeaking = db > -35 // é–¾å€¤ã¯èª¿æ•´å¯èƒ½
        options.onVadUpdate(isSpeaking)
        
        // æ³¢å½¢ãƒ‡ãƒ¼ã‚¿
        options.onWaveformUpdate(dataArray)
        
        animationId = requestAnimationFrame(updateMonitor)
      }
      
      updateMonitor()
      
      // åˆæœŸãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«è¨ˆæ¸¬ï¼ˆ1ç§’å¾Œï¼‰
      setTimeout(() => {
        const noise = calculateNoiseFloor(dataArray)
        options.onNoiseLevel(noise)
      }, 1000)
      
    } catch (error) {
      console.error('ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', error)
    }
  }
  
  function stopMonitoring() {
    isMonitoring.value = false
    if (animationId) cancelAnimationFrame(animationId)
    if (audioContext) audioContext.close()
  }
  
  function calculateNoiseFloor(data: Float32Array): number {
    // ãƒã‚¤ã‚ºãƒ•ãƒ­ã‚¢è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯
    return -50 // ä»®ã®å€¤
  }
  
  onUnmounted(() => {
    stopMonitoring()
  })
  
  return {
    isMonitoring,
    startMonitoring,
    stopMonitoring
  }
}
```

### Step 4: UIå®Ÿè£…
1. å¸¸æ™‚éŸ³å£°ãƒ¢ãƒ‹ã‚¿ãƒ¼ï¼ˆAudioMonitor.vueï¼‰
2. éŒ²éŸ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ï¼ˆAudioRecorder.vueï¼‰
3. è¨­å®šãƒ‘ãƒãƒ«ï¼ˆVADæ„Ÿåº¦ãªã©ï¼‰
4. éŒ²éŸ³å±¥æ­´è¡¨ç¤º

## ğŸ¯ ã“ã‚Œã ã‘ã§å‹•ãï¼

æœ€å°é™ã®æ§‹æˆã§ï¼š
- ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒã‚¤ã‚¯éŒ²éŸ³
- VADã§éŸ³å£°åŒºé–“æ¤œå‡º
- ã‚µãƒ¼ãƒãƒ¼ã«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
- éŒ²éŸ³ä¸€è¦§è¡¨ç¤º

è¤‡é›‘ãªè¨­å®šã‚„èªè¨¼ãªã—ã€‚å€‹äººåˆ©ç”¨ã«æœ€é©ãªã‚·ãƒ³ãƒ—ãƒ«è¨­è¨ˆã§ã™ã€‚

---

**ğŸ“… æ›´æ–°æ—¥**: 2025-06-26  
**ğŸ¯ ã‚³ãƒ³ã‚»ãƒ—ãƒˆ**: ã‚·ãƒ³ãƒ—ãƒ«æœ€å„ªå…ˆã®éŸ³å£°éŒ²éŸ³ã‚·ã‚¹ãƒ†ãƒ 